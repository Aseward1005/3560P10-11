{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aseward1005/3560P10-11/blob/main/CS4650_Big_Data_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authors: Anthony Seward, Nicholas Baron, Sunjay Guttikonda\n",
        "\n",
        "The idea of our project is to take a dataset describing Player Unknown's Battleground (PUBG) matches and use that data to see if we can maybe predict who is most likely to win based on the stats, as well as gain some insight into what stats are the most important in the game.\n",
        "\n",
        "Data set source: https://www.kaggle.com/competitions/pubg-finish-placement-prediction/data\n",
        "\n",
        "Since the target value (`winPlacePerc` in the dataset) ranges from 0 to 1, we will use a linear regressor."
      ],
      "metadata": {
        "id": "vTEb34DVpbkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEYjRBpn1Fqp",
        "outputId": "dacf95de-0000-4a75-b3fa-c00cebf53ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All of the imports\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn import linear_model, datasets, preprocessing\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils"
      ],
      "metadata": {
        "id": "25QPakSG928P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(csv_name: str):\n",
        "    zip_name = ''.join(['drive/MyDrive/pubg_data/', csv_name, '.zip'])\n",
        "    with ZipFile(zip_name) as data:\n",
        "        with data.open(csv_name) as csv:\n",
        "            return pd.read_csv(csv)\n",
        "\n",
        "train_data = read_data('train_V2.csv')"
      ],
      "metadata": {
        "id": "er38en7U7srD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvCbySHLCyPY",
        "outputId": "1155f2f5-8676-4129-c8cb-9e9400603eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4446966 entries, 0 to 4446965\n",
            "Data columns (total 29 columns):\n",
            " #   Column           Dtype  \n",
            "---  ------           -----  \n",
            " 0   Id               object \n",
            " 1   groupId          object \n",
            " 2   matchId          object \n",
            " 3   assists          int64  \n",
            " 4   boosts           int64  \n",
            " 5   damageDealt      float64\n",
            " 6   DBNOs            int64  \n",
            " 7   headshotKills    int64  \n",
            " 8   heals            int64  \n",
            " 9   killPlace        int64  \n",
            " 10  killPoints       int64  \n",
            " 11  kills            int64  \n",
            " 12  killStreaks      int64  \n",
            " 13  longestKill      float64\n",
            " 14  matchDuration    int64  \n",
            " 15  matchType        object \n",
            " 16  maxPlace         int64  \n",
            " 17  numGroups        int64  \n",
            " 18  rankPoints       int64  \n",
            " 19  revives          int64  \n",
            " 20  rideDistance     float64\n",
            " 21  roadKills        int64  \n",
            " 22  swimDistance     float64\n",
            " 23  teamKills        int64  \n",
            " 24  vehicleDestroys  int64  \n",
            " 25  walkDistance     float64\n",
            " 26  weaponsAcquired  int64  \n",
            " 27  winPoints        int64  \n",
            " 28  winPlacePerc     float64\n",
            "dtypes: float64(6), int64(19), object(4)\n",
            "memory usage: 983.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has ~4 million rows and 29 columns.\n",
        "\n",
        "Some columns have additional logic which makes them unsuitable for a linear regression.\n",
        "`killPoints`, `rankPoints`, and `winPoints` have special logic regarding -1 in addition to `rankPoints` being deprecated.\n",
        "Furthermore, `matchType` is a finite set of non-numeric values, which may not play nicely with the regressor.\n",
        "The columns ending in `Id` will also need to be removed both because they are non-numeric (according to Pandas) and because we are looking for win placements regardless of match, group, or specific player.\n",
        "In total, 7 columns need to be removed, leaving 22 for the regressor."
      ],
      "metadata": {
        "id": "xm0dmExk_Ljp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_cleaned = train_data.drop(['Id', 'groupId', 'matchId', 'rankPoints', 'killPoints', 'winPoints', 'matchType'], axis = 1)\n",
        "train_data_cleaned.info()"
      ],
      "metadata": {
        "id": "TCxmzn8rEWFr",
        "outputId": "ee1a49fe-54cf-4651-962f-4fa3b8736db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4446966 entries, 0 to 4446965\n",
            "Data columns (total 22 columns):\n",
            " #   Column           Dtype  \n",
            "---  ------           -----  \n",
            " 0   assists          int64  \n",
            " 1   boosts           int64  \n",
            " 2   damageDealt      float64\n",
            " 3   DBNOs            int64  \n",
            " 4   headshotKills    int64  \n",
            " 5   heals            int64  \n",
            " 6   killPlace        int64  \n",
            " 7   kills            int64  \n",
            " 8   killStreaks      int64  \n",
            " 9   longestKill      float64\n",
            " 10  matchDuration    int64  \n",
            " 11  maxPlace         int64  \n",
            " 12  numGroups        int64  \n",
            " 13  revives          int64  \n",
            " 14  rideDistance     float64\n",
            " 15  roadKills        int64  \n",
            " 16  swimDistance     float64\n",
            " 17  teamKills        int64  \n",
            " 18  vehicleDestroys  int64  \n",
            " 19  walkDistance     float64\n",
            " 20  weaponsAcquired  int64  \n",
            " 21  winPlacePerc     float64\n",
            "dtypes: float64(6), int64(16)\n",
            "memory usage: 746.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_cleaned.describe()"
      ],
      "metadata": {
        "id": "GNP3k1ijHpVy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "52d2f711-8add-441d-915e-b05b5b7a4c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            assists        boosts   damageDealt         DBNOs  headshotKills  \\\n",
              "count  4.446966e+06  4.446966e+06  4.446966e+06  4.446966e+06   4.446966e+06   \n",
              "mean   2.338149e-01  1.106908e+00  1.307171e+02  6.578755e-01   2.268196e-01   \n",
              "std    5.885731e-01  1.715794e+00  1.707806e+02  1.145743e+00   6.021553e-01   \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00   \n",
              "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00   \n",
              "50%    0.000000e+00  0.000000e+00  8.424000e+01  0.000000e+00   0.000000e+00   \n",
              "75%    0.000000e+00  2.000000e+00  1.860000e+02  1.000000e+00   0.000000e+00   \n",
              "max    2.200000e+01  3.300000e+01  6.616000e+03  5.300000e+01   6.400000e+01   \n",
              "\n",
              "              heals     killPlace         kills   killStreaks   longestKill  \\\n",
              "count  4.446966e+06  4.446966e+06  4.446966e+06  4.446966e+06  4.446966e+06   \n",
              "mean   1.370147e+00  4.759935e+01  9.247833e-01  5.439551e-01  2.299759e+01   \n",
              "std    2.679982e+00  2.746294e+01  1.558445e+00  7.109721e-01  5.097262e+01   \n",
              "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%    0.000000e+00  2.400000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%    0.000000e+00  4.700000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%    2.000000e+00  7.100000e+01  1.000000e+00  1.000000e+00  2.132000e+01   \n",
              "max    8.000000e+01  1.010000e+02  7.200000e+01  2.000000e+01  1.094000e+03   \n",
              "\n",
              "       ...     numGroups       revives  rideDistance     roadKills  \\\n",
              "count  ...  4.446966e+06  4.446966e+06  4.446966e+06  4.446966e+06   \n",
              "mean   ...  4.300759e+01  1.646590e-01  6.061157e+02  3.496091e-03   \n",
              "std    ...  2.328949e+01  4.721671e-01  1.498344e+03  7.337297e-02   \n",
              "min    ...  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%    ...  2.700000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%    ...  3.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%    ...  4.700000e+01  0.000000e+00  1.909750e-01  0.000000e+00   \n",
              "max    ...  1.000000e+02  3.900000e+01  4.071000e+04  1.800000e+01   \n",
              "\n",
              "       swimDistance     teamKills  vehicleDestroys  walkDistance  \\\n",
              "count  4.446966e+06  4.446966e+06     4.446966e+06  4.446966e+06   \n",
              "mean   4.509322e+00  2.386841e-02     7.918208e-03  1.154218e+03   \n",
              "std    3.050220e+01  1.673935e-01     9.261157e-02  1.183497e+03   \n",
              "min    0.000000e+00  0.000000e+00     0.000000e+00  0.000000e+00   \n",
              "25%    0.000000e+00  0.000000e+00     0.000000e+00  1.551000e+02   \n",
              "50%    0.000000e+00  0.000000e+00     0.000000e+00  6.856000e+02   \n",
              "75%    0.000000e+00  0.000000e+00     0.000000e+00  1.976000e+03   \n",
              "max    3.823000e+03  1.200000e+01     5.000000e+00  2.578000e+04   \n",
              "\n",
              "       weaponsAcquired  winPlacePerc  \n",
              "count     4.446966e+06  4.446965e+06  \n",
              "mean      3.660488e+00  4.728216e-01  \n",
              "std       2.456544e+00  3.074050e-01  \n",
              "min       0.000000e+00  0.000000e+00  \n",
              "25%       2.000000e+00  2.000000e-01  \n",
              "50%       3.000000e+00  4.583000e-01  \n",
              "75%       5.000000e+00  7.407000e-01  \n",
              "max       2.360000e+02  1.000000e+00  \n",
              "\n",
              "[8 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef4d814f-276c-4c62-8cf3-486bfb7806d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assists</th>\n",
              "      <th>boosts</th>\n",
              "      <th>damageDealt</th>\n",
              "      <th>DBNOs</th>\n",
              "      <th>headshotKills</th>\n",
              "      <th>heals</th>\n",
              "      <th>killPlace</th>\n",
              "      <th>kills</th>\n",
              "      <th>killStreaks</th>\n",
              "      <th>longestKill</th>\n",
              "      <th>...</th>\n",
              "      <th>numGroups</th>\n",
              "      <th>revives</th>\n",
              "      <th>rideDistance</th>\n",
              "      <th>roadKills</th>\n",
              "      <th>swimDistance</th>\n",
              "      <th>teamKills</th>\n",
              "      <th>vehicleDestroys</th>\n",
              "      <th>walkDistance</th>\n",
              "      <th>weaponsAcquired</th>\n",
              "      <th>winPlacePerc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446966e+06</td>\n",
              "      <td>4.446965e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.338149e-01</td>\n",
              "      <td>1.106908e+00</td>\n",
              "      <td>1.307171e+02</td>\n",
              "      <td>6.578755e-01</td>\n",
              "      <td>2.268196e-01</td>\n",
              "      <td>1.370147e+00</td>\n",
              "      <td>4.759935e+01</td>\n",
              "      <td>9.247833e-01</td>\n",
              "      <td>5.439551e-01</td>\n",
              "      <td>2.299759e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>4.300759e+01</td>\n",
              "      <td>1.646590e-01</td>\n",
              "      <td>6.061157e+02</td>\n",
              "      <td>3.496091e-03</td>\n",
              "      <td>4.509322e+00</td>\n",
              "      <td>2.386841e-02</td>\n",
              "      <td>7.918208e-03</td>\n",
              "      <td>1.154218e+03</td>\n",
              "      <td>3.660488e+00</td>\n",
              "      <td>4.728216e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.885731e-01</td>\n",
              "      <td>1.715794e+00</td>\n",
              "      <td>1.707806e+02</td>\n",
              "      <td>1.145743e+00</td>\n",
              "      <td>6.021553e-01</td>\n",
              "      <td>2.679982e+00</td>\n",
              "      <td>2.746294e+01</td>\n",
              "      <td>1.558445e+00</td>\n",
              "      <td>7.109721e-01</td>\n",
              "      <td>5.097262e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.328949e+01</td>\n",
              "      <td>4.721671e-01</td>\n",
              "      <td>1.498344e+03</td>\n",
              "      <td>7.337297e-02</td>\n",
              "      <td>3.050220e+01</td>\n",
              "      <td>1.673935e-01</td>\n",
              "      <td>9.261157e-02</td>\n",
              "      <td>1.183497e+03</td>\n",
              "      <td>2.456544e+00</td>\n",
              "      <td>3.074050e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.400000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>2.700000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.551000e+02</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.424000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.700000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.856000e+02</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>4.583000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.860000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>7.100000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.132000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>4.700000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.909750e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.976000e+03</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>7.407000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.200000e+01</td>\n",
              "      <td>3.300000e+01</td>\n",
              "      <td>6.616000e+03</td>\n",
              "      <td>5.300000e+01</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>8.000000e+01</td>\n",
              "      <td>1.010000e+02</td>\n",
              "      <td>7.200000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>1.094000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+02</td>\n",
              "      <td>3.900000e+01</td>\n",
              "      <td>4.071000e+04</td>\n",
              "      <td>1.800000e+01</td>\n",
              "      <td>3.823000e+03</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>2.578000e+04</td>\n",
              "      <td>2.360000e+02</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef4d814f-276c-4c62-8cf3-486bfb7806d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef4d814f-276c-4c62-8cf3-486bfb7806d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef4d814f-276c-4c62-8cf3-486bfb7806d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes on Histograms\n",
        "The duration histogram has 3 spikes: one just before 1000 seconds, one just before 1500, and one before 2000.\n",
        "Most histograms have negative trends, which coorelates with skill in that particular statistic.\n",
        "The drop in `killPlace` means that ranks 90 to 100 often do not have any kills."
      ],
      "metadata": {
        "id": "Rh1sqbZfKugp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram because 72 kills is REALLY high (from a player of the game)\n",
        "#show histograms for overall data\n",
        "colors = list(mcolors.CSS4_COLORS.keys())[10:]\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i, feature in enumerate(train_data_cleaned.columns):\n",
        "    f = fig.add_subplot(8, 4, i + 1)\n",
        "    train_data_cleaned[feature].hist(bins = 20, ax = f, facecolor = colors[i])\n",
        "    f.set_title(feature + \" Histogram\", color = colors[35])\n",
        "    f.set_yscale('log')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w67H1LXhInr9",
        "outputId": "0ad4489c-4ce0-472b-e7f2-da6e48f93aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 22 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input contains NaN, infinity, or value too large for float64, meaning this is a float64, this can be in either damageDealt, longestKill, rideDistance, swimDistance, or winPlacePerc. It doesn't say which one, meaning we have to do some testing to find it"
      ],
      "metadata": {
        "id": "wGb1M3yvXqA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for some reason 2744604 is null, we will remove that row from the data"
      ],
      "metadata": {
        "id": "qchVryBVaSkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split x and y train set\n",
        "y_train = train_data_cleaned['winPlacePerc']\n",
        "x_train = train_data_cleaned.iloc[:, train_data_cleaned.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "DVuFFZkyaxmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train['damageDealt'].isnull().values.any())\n",
        "print(x_train['longestKill'].isnull().values.any())\n",
        "print(x_train['rideDistance'].isnull().values.any())\n",
        "print(x_train['swimDistance'].isnull().values.any())\n",
        "print(y_train.isnull().values.any())\n",
        "print([i for i, val in enumerate(y_train.isnull().values) if val])\n",
        "print(y_train[2744604])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "md5Ck2LlYE_v",
        "outputId": "ee88a3e0-7e99-417a-834b-79620c9899bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "[]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2744604",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ff2032d5facd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2744604\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2744604"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_cleaned.drop(index = 2744604, axis = 0, inplace = True)"
      ],
      "metadata": {
        "id": "x1ATFFqgaXI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split x and y train set\n",
        "y_train = train_data_cleaned['winPlacePerc']\n",
        "x_train = train_data_cleaned.iloc[:, train_data_cleaned.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "GG4QnZHHWkya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "yhat = model.predict(x_train)\n",
        "\n",
        "#output the mean square error\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {model.score(x_train, y_train)}')"
      ],
      "metadata": {
        "id": "qbYFRiG4azqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453d1e3e-7e8f-48e9-b1f5-9a2d2af57c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.13\n",
            "Score: 0.8295834124511875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXQfbcS4ccJ8",
        "outputId": "e7fc6596-525f-4fe1-c1d3-49ed63642517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.45605002e-02,  1.44684449e-02,  5.82494660e-05, -4.70786724e-03,\n",
              "        1.84470759e-03,  7.15778725e-04, -7.03493212e-03, -1.51448047e-02,\n",
              "       -1.34830073e-01,  9.48757316e-06, -1.60688179e-04, -7.47157796e-03,\n",
              "        8.87797736e-03,  1.41222304e-02,  1.80900751e-05,  1.46760143e-02,\n",
              "        1.09811205e-04, -1.49135885e-02,  9.45218772e-03,  1.14967742e-04,\n",
              "        1.12535271e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the coefficients seem small, so normalizing the input data may help find which features are less important."
      ],
      "metadata": {
        "id": "NDk5NLxMCLip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train_scaled = scalar.transform(x_train)\n",
        "\n",
        "scaled_model = linear_model.LinearRegression()\n",
        "scaled_model.fit(x_train_scaled, y_train)\n",
        "yhat = scaled_model.predict(x_train_scaled)\n",
        "\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {scaled_model.score(x_train_scaled, y_train)}')"
      ],
      "metadata": {
        "id": "nUyqqqxGcdTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c188bae-bac9-4f9d-9511-e293c4aa0714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.13\n",
            "Score: 0.8295834124511876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_model.coef_"
      ],
      "metadata": {
        "id": "4KXn3fsXIV-e",
        "outputId": "b37bf602-00ea-4f87-daa7-52f1a86db200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00856992,  0.02482487,  0.00994788, -0.005394  ,  0.0011108 ,\n",
              "        0.00191827, -0.19319984, -0.02360234, -0.09586041,  0.00048361,\n",
              "       -0.04157626, -0.17803348,  0.20676353,  0.00666805,  0.02710515,\n",
              "        0.00107682,  0.00334948, -0.00249644,  0.00087538,  0.13606397,\n",
              "        0.02764477])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaled Lasso Model"
      ],
      "metadata": {
        "id": "YEJUZ4rMVnya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso = linear_model.Lasso(alpha = .3)\n",
        "scaled_lasso.fit(x_train_scaled, y_train)\n",
        "yhat = scaled_lasso.predict(x_train_scaled)\n",
        "\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {scaled_model.score(x_train_scaled, y_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0SBKaX9ViYU",
        "outputId": "36cf6923-0f63-4496-a530-73a42f4cc004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.31\n",
            "Score: 0.8295834124511876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK0hsGP0WKQ5",
        "outputId": "f4aae548-9923-469d-9ec8-e996ee4395e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ERpmuGWz65",
        "outputId": "5e48dc41-8ea2-44c3-ee70-615f2464c6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4728215527219128"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regressor in this way always guesses 47th place. It places a straight line on the mean and says \"no point trying to rationalize, just guess 47 and you will be right 82.9% of the time\"\n",
        "\n",
        "Looks like an underfitting problem."
      ],
      "metadata": {
        "id": "565sZmcRXLuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple options from here, we can do some sampling. Maybe the dataset is just too large with too many 47's, and splitting the dataset into smaller samples will allow the regressor to pick up on more data. We can then do something like a random forest and combine the regressors from the smaller datasets.\n",
        "\n",
        "We can average all the data from the same datapoints and massively shrink our dataset\n",
        "\n",
        "We can try a different type of classifier (neural nets are fun)\n",
        "(actually do a polynomial model, not neural net yet)\n",
        "\n",
        "Or maybe it really doesn't matter and pubg is just too random of a game (I don't like this answer)\n",
        "\n",
        "We probably should try to work back in the ranking data though."
      ],
      "metadata": {
        "id": "Vf2Yv7rYZDUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First we try to include rankings\n",
        "\n",
        "Logic: if there is a -1 in rankPoints, it is counted as a none, we remove those.\n",
        "Then if there is a 0 in winPoints or killPoints, those are also counted as none, we remove those.\n",
        "Then the dataset says that rankPoints is inconsistent. We thus remove that column (but maybe the inconsistency is offset by how large the dataset is? it's worth testing.)"
      ],
      "metadata": {
        "id": "x5fP6Z4FfCHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_cleaned2 = train_data[train_data['rankPoints'] != -1]\n",
        "train_data_cleaned2 = train_data_cleaned2[train_data_cleaned2['winPoints'] != 0]\n",
        "train_data_cleaned2 = train_data_cleaned2[train_data_cleaned2['killPoints'] != 0]\n",
        "train_data_cleaned2.drop(['Id', 'groupId', 'matchId', 'matchType'], axis = 1, inplace = True)\n",
        "\n",
        "#train_data_cleaned2.drop(index = 2744604, axis = 0, inplace = True) #remove the dumb dumb that messed us up earlier\n",
        "# that datapoint actually didn't have rankpoints or winpoints or killpoints so it doesn't matter\n",
        "\n",
        "train_data_cleaned2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIG-Rz_IXAww",
        "outputId": "502dff63-edf1-48fb-d18c-093334b0be5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 89509 entries, 19 to 4446935\n",
            "Data columns (total 25 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   assists          89509 non-null  int64  \n",
            " 1   boosts           89509 non-null  int64  \n",
            " 2   damageDealt      89509 non-null  float64\n",
            " 3   DBNOs            89509 non-null  int64  \n",
            " 4   headshotKills    89509 non-null  int64  \n",
            " 5   heals            89509 non-null  int64  \n",
            " 6   killPlace        89509 non-null  int64  \n",
            " 7   killPoints       89509 non-null  int64  \n",
            " 8   kills            89509 non-null  int64  \n",
            " 9   killStreaks      89509 non-null  int64  \n",
            " 10  longestKill      89509 non-null  float64\n",
            " 11  matchDuration    89509 non-null  int64  \n",
            " 12  maxPlace         89509 non-null  int64  \n",
            " 13  numGroups        89509 non-null  int64  \n",
            " 14  rankPoints       89509 non-null  int64  \n",
            " 15  revives          89509 non-null  int64  \n",
            " 16  rideDistance     89509 non-null  float64\n",
            " 17  roadKills        89509 non-null  int64  \n",
            " 18  swimDistance     89509 non-null  float64\n",
            " 19  teamKills        89509 non-null  int64  \n",
            " 20  vehicleDestroys  89509 non-null  int64  \n",
            " 21  walkDistance     89509 non-null  float64\n",
            " 22  weaponsAcquired  89509 non-null  int64  \n",
            " 23  winPoints        89509 non-null  int64  \n",
            " 24  winPlacePerc     89509 non-null  float64\n",
            "dtypes: float64(6), int64(19)\n",
            "memory usage: 17.8 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This took the dataset down from 4 mill to 90000.\n",
        "\n",
        "Hopefully there is no more underfitting, as we removed a bunch of datapoints AND added features to the dataset"
      ],
      "metadata": {
        "id": "rc_L90_nhPZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split x and y train set\n",
        "y_train = train_data_cleaned2['winPlacePerc']\n",
        "x_train = train_data_cleaned2.iloc[:, train_data_cleaned2.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "2U3-7J99hGWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "yhat = model.predict(x_train)\n",
        "\n",
        "#output the mean square error\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {model.score(x_train, y_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJdhBdbHjklm",
        "outputId": "880b76fe-16fd-4ec8-a91d-e0d59e692d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.12\n",
            "Score: 0.8490990348058034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score is 2 percent better, I'll take it, but also maybe the score is better because we have a smaller dataset"
      ],
      "metadata": {
        "id": "SY4xQxk0j0OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3aKmop3ju4G",
        "outputId": "654254bc-9658-480f-e505-dd1f29423ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25419185e-02,  1.42639013e-02,  6.41991371e-05, -1.80816911e-04,\n",
              "        1.44938659e-03,  1.12045062e-03, -7.10586924e-03, -6.07562396e-05,\n",
              "       -1.71090376e-02, -1.37705941e-01, -1.69356988e-06, -1.83091555e-04,\n",
              "       -4.51098834e-03,  5.81433528e-03,  3.55618313e-17,  1.62038606e-02,\n",
              "        1.66270909e-05, -1.06753377e-02,  9.06695228e-05, -3.00658121e-02,\n",
              "        1.33936264e-02,  1.16190373e-04,  1.17053512e-02,  2.18714543e-04])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients are still very low, so LASSO will probably still scale this all down to 0"
      ],
      "metadata": {
        "id": "fGnVItcOkBZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train_scaled = scalar.transform(x_train)\n",
        "\n",
        "scaled_model = linear_model.LinearRegression()\n",
        "scaled_model.fit(x_train_scaled, y_train)\n",
        "yhat = scaled_model.predict(x_train_scaled)\n",
        "\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {scaled_model.score(x_train_scaled, y_train)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYY0Q00Ij6tW",
        "outputId": "5209ab30-54f7-4d6d-bba5-a21837b7ba9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.12\n",
            "Score: 0.8490990348058034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso = linear_model.Lasso(alpha = .3)\n",
        "scaled_lasso.fit(x_train_scaled, y_train)\n",
        "yhat = scaled_lasso.predict(x_train_scaled)\n",
        "\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {scaled_model.score(x_train_scaled, y_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ORlluakLOW",
        "outputId": "b19c2887-1652-4363-c168-a0540ce8bba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.31\n",
            "Score: 0.8490990348058034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5A0_82TkOX_",
        "outputId": "87629978-74bb-4e91-e860-162b3203a24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_lasso.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU3nyRQQkV9N",
        "outputId": "9abe96d6-d449-43f3-cc2d-dc54075a6bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47047983778167557"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It says rankPoints is being deprecated, so we now remove that and see if the regressor performs any better (we are still underfitting, so I suspect it won't change much)"
      ],
      "metadata": {
        "id": "ucqETyPXkyWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_cleaned3 = train_data_cleaned2.drop('rankPoints', axis = 1)"
      ],
      "metadata": {
        "id": "zSNzckBckYcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split x and y train set\n",
        "y_train = train_data_cleaned3['winPlacePerc']\n",
        "x_train = train_data_cleaned3.iloc[:, train_data_cleaned3.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "KiSTtVH4lE4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "yhat = model.predict(x_train)\n",
        "\n",
        "#output the mean square error\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {model.score(x_train, y_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbOxxd7xlLL9",
        "outputId": "1a29dc54-533f-4bce-a84b-b9b4d1456dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.12\n",
            "Score: 0.8490990348058034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, this didn't really do much. We're gonna need a more complicated model"
      ],
      "metadata": {
        "id": "D-QYeKOJlSTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#start with linear connection, and reLU all the way through\n",
        "class Regressor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(24, 48).to(torch.float64)\n",
        "\n",
        "    self.linear2 = nn.Linear(48, 24).to(torch.float64)\n",
        "\n",
        "    self.linear3 = nn.Linear(24, 12).to(torch.float64)\n",
        "\n",
        "    self.linear4 = nn.Linear(12, 6).to(torch.float64)\n",
        "    self.out = nn.Linear(6, 1).to(torch.float64)\n",
        "\n",
        "    #activation function is constant\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    hidden1 = self.linear1(x)\n",
        "    hidden1 = self.act(hidden1)\n",
        "\n",
        "    hidden2 = self.linear2(hidden1)\n",
        "    hidden2 = self.act(hidden2)\n",
        "\n",
        "    hidden3 = self.linear3(hidden2)\n",
        "    hidden3 = self.act(hidden3)\n",
        "\n",
        "    hidden4 = self.linear4(hidden3)\n",
        "    hidden4 = self.act(hidden4)\n",
        "\n",
        "    out = self.out(hidden4)\n",
        "    return self.act(out)"
      ],
      "metadata": {
        "id": "bluj81FvlNrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_regressor(opt, model, loader, epochs = 5):\n",
        "  #loss function definition\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  for i in range(epochs):\n",
        "    print(f'epoch{i}')\n",
        "    #train the model on the minibatch\n",
        "    for inputs, targets in loader:\n",
        "      #zero the gradient\n",
        "      opt.zero_grad()\n",
        "\n",
        "      #calculate predictions for given x\n",
        "      x_pred = model(inputs)\n",
        "      #calculate loss vs given y\n",
        "      loss = loss_fn(x_pred, targets)\n",
        "      #calculate the gradient\n",
        "      loss.backward()\n",
        "\n",
        "      #print the loss\n",
        "      print(loss)\n",
        "\n",
        "      #perform an optimizer step\n",
        "      opt.step()"
      ],
      "metadata": {
        "id": "ArI1EX33oWr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#im not gonna lie, chatgpt is a godsend\n",
        "class tensorSet(data_utils.Dataset):\n",
        "  def __init__(self, data, targets):\n",
        "    # Store the data and targets\n",
        "    self.data = data.to_numpy()\n",
        "    self.data = torch.from_numpy(self.data)\n",
        "\n",
        "    self.targets = targets.to_numpy()\n",
        "    self.targets = torch.from_numpy(self.targets)\n",
        "\n",
        "  def __len__(self):\n",
        "    # Return the length of the dataset\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Get the data point and target at the given index\n",
        "    data_point = self.data[index]\n",
        "    target = self.targets[index]\n",
        "\n",
        "    return data_point, target"
      ],
      "metadata": {
        "id": "NeLPr_-d4aX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "im running into issues and running out of patience, I'm just gonna hardcode the parameters"
      ],
      "metadata": {
        "id": "unGBtc-rruHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKCKT8LRrSq4",
        "outputId": "b307907a-a929-4fad-8e8d-f062a6589040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Regressor()\n",
        "optimizer = torch.optim.Adam(regressor.parameters(), lr = .0001)\n",
        "\n",
        "dataset = tensorSet(x_train, y_train)\n",
        "\n",
        "dataloader = data_utils.DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "train_regressor(optimizer, regressor, dataloader)"
      ],
      "metadata": {
        "id": "_cbRmd7Soo6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = regressor(torch.from_numpy(x_train.to_numpy()))\n",
        "ypred = torch.clamp(ypred, 0, 1)\n",
        "\n",
        "print(np.sqrt(mean_squared_error(torch.from_numpy(y_train.to_numpy(y_train)).detach().numpy(), ypred.detach().numpy())))\n",
        "print(r2_score(torch.from_numpy(y_train.to_numpy()).detach().numpy(), ypred.detach().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "vqar7knWq8pX",
        "outputId": "0d9d4c70-c623-444b-a19b-671b3656f442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d33a74928e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#TODO: make these more readable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'regressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the model is performing extremely poorly, not only that, it somehow performs BETTER when it isn't clamped. What? (we updated the model to add more neurons in the hidden layers and now it more accurately represents the dataset)"
      ],
      "metadata": {
        "id": "Ej3t1mVkCnXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data"
      ],
      "metadata": {
        "id": "pDAb5m08iOWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data preprocessing\n",
        "\n",
        "we used dataset 2, so the preprocessing should be the same"
      ],
      "metadata": {
        "id": "wTb2bI7ehiov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = read_data('test_V2.csv')"
      ],
      "metadata": {
        "id": "JYKchTZbFFRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_cleaned2 = test_data[test_data['rankPoints'] != -1]\n",
        "test_data_cleaned2 = test_data_cleaned2[test_data_cleaned2['winPoints'] != 0]\n",
        "test_data_cleaned2 = test_data_cleaned2[test_data_cleaned2['killPoints'] != 0]\n",
        "test_data_cleaned2.drop(['Id', 'groupId', 'matchId', 'matchType'], axis = 1, inplace = True)\n",
        "\n",
        "test_data_cleaned2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZOOWtMFhhNM",
        "outputId": "9d88f644-b1a0-4c3b-d018-1ad58ed0a81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 41429 entries, 37 to 1934073\n",
            "Data columns (total 24 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   assists          41429 non-null  int64  \n",
            " 1   boosts           41429 non-null  int64  \n",
            " 2   damageDealt      41429 non-null  float64\n",
            " 3   DBNOs            41429 non-null  int64  \n",
            " 4   headshotKills    41429 non-null  int64  \n",
            " 5   heals            41429 non-null  int64  \n",
            " 6   killPlace        41429 non-null  int64  \n",
            " 7   killPoints       41429 non-null  int64  \n",
            " 8   kills            41429 non-null  int64  \n",
            " 9   killStreaks      41429 non-null  int64  \n",
            " 10  longestKill      41429 non-null  float64\n",
            " 11  matchDuration    41429 non-null  int64  \n",
            " 12  maxPlace         41429 non-null  int64  \n",
            " 13  numGroups        41429 non-null  int64  \n",
            " 14  rankPoints       41429 non-null  int64  \n",
            " 15  revives          41429 non-null  int64  \n",
            " 16  rideDistance     41429 non-null  float64\n",
            " 17  roadKills        41429 non-null  int64  \n",
            " 18  swimDistance     41429 non-null  float64\n",
            " 19  teamKills        41429 non-null  int64  \n",
            " 20  vehicleDestroys  41429 non-null  int64  \n",
            " 21  walkDistance     41429 non-null  float64\n",
            " 22  weaponsAcquired  41429 non-null  int64  \n",
            " 23  winPoints        41429 non-null  int64  \n",
            "dtypes: float64(5), int64(19)\n",
            "memory usage: 7.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test = test_data_cleaned2['winPlacePerc'], the \"test\" dataset doesn't actually have the values built in because this is a competition, so we can predict, but we won't know how good our predictions are\n",
        "x_test = test_data_cleaned2.iloc[:, test_data_cleaned2.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "wifhO1oEiVpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data predictions"
      ],
      "metadata": {
        "id": "b69TH2wTiLxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ypred = regressor(torch.from_numpy(x_test.to_numpy()))\n",
        "ypred = torch.clamp(ypred, 0, 1)"
      ],
      "metadata": {
        "id": "6yk3_M0ch-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can print/visualize this but there is no way to actually check if my predictions are good. I need to actually do a train/test split on the original dataset"
      ],
      "metadata": {
        "id": "bgi-kKaZi9NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "ka2tplVJjV3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split x and y train set\n",
        "y_train = train_data_cleaned2['winPlacePerc']\n",
        "x_train = train_data_cleaned2.iloc[:, train_data_cleaned2.columns != 'winPlacePerc']"
      ],
      "metadata": {
        "id": "ohwrhAJjlQyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SU0awTjokkey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build and train the regressor on the training data\n",
        "regressor = Regressor()\n",
        "optimizer = torch.optim.Adam(regressor.parameters(), lr = .0001)\n",
        "\n",
        "dataset = tensorSet(x_train, y_train)\n",
        "\n",
        "dataloader = data_utils.DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "train_regressor(optimizer, regressor, dataloader)\n",
        "\n",
        "#test the regressor on the training data\n",
        "ypred = regressor(torch.from_numpy(x_train.to_numpy()))\n",
        "ypred = torch.clamp(ypred, 0, 1)\n",
        "print(np.sqrt(mean_squared_error(ypred.detach().numpy(), torch.from_numpy(y_train.to_numpy(y_train)).detach().numpy())))\n",
        "print(r2_score(torch.from_numpy(y_train.to_numpy()).detach().numpy(), ypred.detach().numpy()))"
      ],
      "metadata": {
        "id": "S7lRcvVMi6gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b12385a-1089-4ea3-82dd-9629715d1124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch0\n",
            "tensor(8.1204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.8179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(3.7114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.4334, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6352, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(2.6292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2677, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(3.4077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0478, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(3.2541, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.5498, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(3.4389, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(2.1648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(4.6509, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(3.4560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6265, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(2.6116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.9235, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.9576, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.8290, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.3525, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.3067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.9839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.2280, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3696, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.5568, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.8065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(1.1612, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7706, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5795, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5724, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3336, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4555, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3737, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3234, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4170, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3298, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3394, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3171, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2658, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3386, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2745, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2698, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3406, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3349, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3327, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3418, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3713, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3713, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3345, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3634, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3425, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3674, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2467, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3455, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2533, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3738, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3601, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3790, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2464, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2718, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2699, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3459, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2722, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3587, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2694, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3485, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3333, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3563, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2651, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2367, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2470, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3301, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3714, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3356, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2734, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2465, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3409, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2759, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2481, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2438, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3248, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2280, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3355, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3469, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2582, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3324, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2336, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2752, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3441, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2451, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3586, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3576, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3229, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3585, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3495, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2738, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2684, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2486, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2689, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3417, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2700, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2561, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3569, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3384, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3322, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3314, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3523, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2730, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3631, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2702, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2363, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3528, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3695, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2937, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2502, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2626, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3474, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3548, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3775, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3533, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3397, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3255, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2498, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3427, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3766, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3251, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3637, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3436, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2413, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3494, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3525, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3342, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2769, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3277, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2579, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3698, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2600, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3344, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3685, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3723, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2442, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3341, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3254, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2379, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2735, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3437, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3608, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2750, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2739, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3654, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3354, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3854, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3530, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3425, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2511, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3384, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2678, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2725, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2753, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2453, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3456, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2788, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2301, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3401, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2882, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3314, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2569, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3340, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3420, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3562, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2687, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2583, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2694, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3337, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3401, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3550, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3363, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3643, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3448, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3480, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2361, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2620, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3701, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3467, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3357, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2268, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3578, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3212, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2561, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3480, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3322, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3696, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2771, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2777, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3632, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2731, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3342, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3256, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3274, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2509, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3725, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3232, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3377, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3383, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3233, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2645, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2724, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3581, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3305, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3224, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3232, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3519, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3283, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3745, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3200, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3350, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2563, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2622, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2792, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3511, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2592, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2638, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3308, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3252, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2687, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3416, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3291, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2387, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2663, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2594, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2559, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3534, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4405, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3488, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3238, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2568, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3572, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3272, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2884, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3229, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2468, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2749, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2760, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2668, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3284, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2429, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3298, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3749, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2612, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3350, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3450, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3320, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3375, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2395, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3290, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3428, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3456, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3536, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2787, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3218, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3229, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2593, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3663, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3693, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3401, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2698, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2348, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3629, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3257, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3491, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3221, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3498, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3522, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3537, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2445, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2659, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3320, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2680, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3293, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3484, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2875, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2473, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3390, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3186, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3251, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3460, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3544, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3441, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2325, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2776, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3234, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3266, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3486, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3180, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3295, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3474, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3419, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2740, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3339, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3189, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3682, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3632, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3329, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2437, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2592, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2757, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2729, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3750, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2441, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3225, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3702, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3324, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2756, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2609, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2757, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3578, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3291, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2665, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3568, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2841, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2619, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3371, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3414, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3419, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3557, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2314, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3558, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3418, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2741, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2587, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2727, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2732, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3652, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2537, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3764, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3391, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3699, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2436, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3307, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2639, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2504, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2579, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3615, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3255, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2553, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2755, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3387, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3318, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2696, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3267, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3459, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3456, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2651, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2716, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2792, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2875, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2616, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3755, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2544, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2376, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2779, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2733, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2716, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3588, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3134, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2715, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2624, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3386, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3416, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2565, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2435, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3248, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3469, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3544, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3582, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3345, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2509, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3431, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3442, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3464, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3243, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3462, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3287, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3462, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3393, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2528, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3412, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2683, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3177, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3586, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2633, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2726, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3625, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2775, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3736, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3444, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3630, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2588, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3502, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3241, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3608, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2525, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2278, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3337, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3562, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2563, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2665, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3256, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3548, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3288, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3813, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2461, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3413, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3590, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3311, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2721, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2468, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3412, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3303, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3389, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3502, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3309, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3211, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3303, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3408, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2265, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3565, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3256, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3393, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2655, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3367, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3430, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3303, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2591, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3426, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2589, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2717, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2456, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "epoch1\n",
            "tensor(0.3269, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3793, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2788, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2728, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3601, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2681, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3613, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3619, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2742, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([55])) that is different to the input size (torch.Size([55, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3290, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3577, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3613, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3352, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2748, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3452, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2833, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3247, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3242, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3720, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2666, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2768, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2755, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2790, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2741, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3268, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3789, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3450, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3487, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2776, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2675, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3308, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3533, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2483, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3506, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3461, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3625, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2738, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2875, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2376, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3287, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3607, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3737, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2428, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2777, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2492, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3262, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2551, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2633, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3151, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3374, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2259, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2750, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3607, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3340, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2336, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3391, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2811, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2506, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2791, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2799, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2609, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3698, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3304, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2785, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2610, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3239, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3388, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3384, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3552, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2715, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2645, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4239, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3422, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3470, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2314, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3361, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3547, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3741, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3217, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2739, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3350, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3180, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3468, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2854, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2571, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2606, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2723, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2314, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3551, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2750, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3294, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2686, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3655, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2654, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2519, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3647, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3373, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2703, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3232, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2674, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3283, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3507, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2799, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2614, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3580, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3763, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3419, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2722, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2719, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3636, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3404, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2530, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2461, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2406, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3252, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2658, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2462, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3571, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3214, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2716, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2705, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2584, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3455, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3628, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3688, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2684, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2787, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2283, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3630, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2566, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3553, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2723, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2533, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2640, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3680, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3363, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2654, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2325, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3311, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2778, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3257, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3459, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2735, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2225, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2696, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3652, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3235, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3587, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3458, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2550, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3441, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3591, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3363, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2667, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2788, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2559, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3572, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3466, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2272, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3493, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3343, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2727, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2585, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3415, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2752, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2875, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3486, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3328, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3498, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3674, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2617, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2722, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3724, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2674, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2230, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3427, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2775, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3683, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2694, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2507, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2593, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2841, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2450, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2635, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2536, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3418, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3311, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3517, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3262, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2722, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3293, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2594, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2414, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2355, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2629, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3289, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2497, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2273, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2552, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2273, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3196, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2391, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2813, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2670, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3549, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2768, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3309, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3358, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3423, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2486, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2488, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3354, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3432, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2704, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3091, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2589, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2783, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3459, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2590, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2700, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3197, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2460, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2482, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2322, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2778, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3419, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2435, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2681, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2791, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2399, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3316, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3475, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2480, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3759, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2563, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2595, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3518, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3338, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3440, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2673, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3334, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2842, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2557, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3446, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3695, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3444, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2561, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2399, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2471, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2723, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2761, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3497, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2733, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3166, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2547, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2461, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3305, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2725, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3229, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3289, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3358, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2308, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2699, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2592, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2444, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2376, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2481, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3282, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2532, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2638, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3381, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2659, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3435, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3576, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3338, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3752, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3200, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3273, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2811, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2569, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2675, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2386, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2383, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3390, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2736, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2736, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2678, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2689, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3795, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3293, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2717, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2736, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2743, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3315, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2770, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3695, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3275, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2772, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2359, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3493, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2691, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2474, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2741, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2650, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2512, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3532, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3332, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2713, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3346, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3288, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3466, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2665, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2731, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3465, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3760, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2743, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2788, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2597, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2787, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2691, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2595, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2487, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2610, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2295, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2345, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2389, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2469, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2277, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2691, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2442, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2339, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2358, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1836, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1538, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1529, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1523, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1659, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1481, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1745, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1618, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1541, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1429, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1673, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1543, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1482, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1389, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1394, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1470, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1389, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1697, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1471, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1586, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1514, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1717, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1401, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1437, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1393, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1683, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1453, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1391, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1493, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0833, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1491, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1503, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1473, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0792, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "epoch2\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1393, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0745, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1421, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1388, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0756, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0753, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1425, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0783, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0882, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0835, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1397, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0841, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0716, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0833, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0884, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0882, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0854, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0811, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0793, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0755, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0875, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0761, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0836, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "epoch3\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0764, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0789, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0742, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0730, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0725, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0841, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0790, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0735, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0756, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0757, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0662, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0739, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0882, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0792, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0836, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0777, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1509, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0854, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0695, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0761, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0825, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0785, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0841, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0896, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0761, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0772, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0842, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0819, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0769, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0762, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0937, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0793, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0772, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0836, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0835, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0737, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0756, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0701, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0937, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0819, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0630, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0815, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0712, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "epoch4\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0869, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0702, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0825, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0811, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0845, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0882, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0733, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0720, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0819, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0736, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0757, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0937, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0769, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0791, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0825, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0741, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0796, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0661, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0832, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0742, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0785, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0721, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0792, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0833, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0795, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0772, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0742, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0684, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0714, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0779, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0727, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0849, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0854, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0688, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0949, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0853, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0842, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0813, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0761, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0933, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0729, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0863, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0893, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0775, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0813, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0831, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0834, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0754, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0849, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0866, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0783, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0864, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0768, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0892, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0813, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0817, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0631, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0874, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0938, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0911, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0939, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0884, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0780, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0899, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0891, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0819, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0822, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0914, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0750, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0680, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0902, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "0.31385693937570724\n",
            "-0.05559419079778305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations"
      ],
      "metadata": {
        "id": "pa01ksqyj9dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test the regressor on the testing data\n",
        "ypred = regressor(torch.from_numpy(x_test.to_numpy()))\n",
        "ypred = torch.clamp(ypred, 0, 1)\n",
        "print(np.sqrt(mean_squared_error(torch.from_numpy(y_test.to_numpy(y_train)).detach().numpy(), ypred.detach().numpy())))\n",
        "print(r2_score(torch.from_numpy(y_test.to_numpy()).detach().numpy(), ypred.detach().numpy()))"
      ],
      "metadata": {
        "id": "eV3oZUx_j7Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e5f416-d09c-4df5-be4f-e7b56e9ea0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.31440922283508166\n",
            "-0.05148603661409079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations: DID WE OVERFIT? NO, WE DID NOT OVERFIT\n",
        "\n",
        "The MLP is about as good as just guessing a straight line, the parameters likely aren't correctly tuned, but the linear model beats it by a lot.\n",
        "\n",
        "This leads to the conclusion that maybe there really is a linear relationship between the attributes and the final placement, even though the coefficients are low. The linear model will be run again below on the new test/train split"
      ],
      "metadata": {
        "id": "mX_Tg2P1kM9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create the linear regression model\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "yhat = model.predict(x_train)\n",
        "\n",
        "#output the mean square error\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_train)):.2f}')\n",
        "print(f'Score: {model.score(x_train, y_train)}') #score is the r2 value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22723d32-96ca-435c-d244-7f2062712967",
        "id": "lpZYLbqfsJdC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.12\n",
            "Score: 0.8496849222318815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run it on the test set\n",
        "yhat = model.predict(x_test)\n",
        "\n",
        "#output the mean square error\n",
        "print(f'Mean-square error: {np.sqrt(mean_squared_error(yhat, y_test)):.2f}')\n",
        "print(f'Score: {model.score(x_test, y_test)}') #score is the r2 value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjO4SqqntTOy",
        "outputId": "240af40f-85f7-479c-b055-2c5e5fbc2279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean-square error: 0.12\n",
            "Score: 0.8466700942668469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients of a linear regression model for this dataset are very low, We thought maybe LASSO would raise some coefficients, while lowering the others, but it actually lowered all the coefficients to zero and just predicted the mean in all cases. This led to the idea that our model was underfitting the dataset, and that a linear relationship was not correct.\n",
        "\n",
        "We then went toward using a multilayer perceptron to model some sort of nonlinear relationship (that the neural net could figure out). After training and tuning the hyperparameters for a few hours, it was found that a linear model fit much better, even though the coefficients are very low.\n",
        "\n",
        "Our observation was that the low coefficients meant there was a low emphasis on all the data, and thus a linear model was not a good fit. After modeling with an MLP and discovering that was ALSO not a good fit (maybe the perceptron is poorly tuned), it was discovered that a nonlinear model also doesn't work. This leads to the conclusion that maybe none of the datapoints matter, or at least, none of them matter very much.\n",
        "\n",
        "There are definitely players that are better at the game than others, and those players will tend to win more and score higher. There is a professional PUBG scene for a reason, so to say that there is no good way to predict whether a player will come on top just sounds incorrect.\n",
        "\n",
        "There is an element of randomness in PUBG, and the best players know how to work around the randomness and strategize in ways that make the game work in their favor. Maybe none of the datapoints are a good fit because they don't adequately show the strategy of a good player. A linear model fits this better than just always guessing the mean because the datapoints represent elements of that strategy, but the low coefficients point to the idea that securing a win in pubg is about more than the stats described here.\n",
        "\n",
        "We will now turn to rank the coefficients in order of importance, as well as find the set of coefficients that will most accurately fit with a linear model (This is Anthony's code from homework 3 (logistic regression) being repurposed)"
      ],
      "metadata": {
        "id": "lz2tnuMvyfsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bad function design, does multiple things. makes a new train/test split,\n",
        "#fits the model to it,\n",
        "#and gives back the train test split\n",
        "\n",
        "def refactor(x, y, model):\n",
        "    #split the data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=12)\n",
        "\n",
        "    #scale the data\n",
        "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "    x_train_scaled = pd.DataFrame(scaler.transform(x_train), columns = x_train.columns)\n",
        "    x_test_scaled = pd.DataFrame(scaler.transform(x_test), columns = x_test.columns)\n",
        "\n",
        "    #fit the model\n",
        "    model.fit(x_train_scaled, y_train)\n",
        "\n",
        "    #return the model and the split data\n",
        "    return x_train_scaled, x_test_scaled, y_train, y_test"
      ],
      "metadata": {
        "id": "dEwuiZ4E4MWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print and return the r2 score of the model\n",
        "\n",
        "def acc_check(x_train, x_test, y_train, y_test, model):\n",
        "    train_accuracy = model.score(x_train, y_train)\n",
        "    print(f'The accuracy for the training set is {100 * train_accuracy:.2f}%')\n",
        "    test_accuracy = model.score(x_test, y_test)\n",
        "    print(f'The accuracy for the test set is {100 * test_accuracy:.2f}%\\n')\n",
        "\n",
        "    return train_accuracy, test_accuracy"
      ],
      "metadata": {
        "id": "KoAMFp6i4XLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate through all 24 columns, removing them one by one in order of smallest to largest\n",
        "#output the r2 value of each combination, as well as what the combination is\n",
        "\n",
        "#the best model should be the one with the highest r2 value\n",
        "\n",
        "\n",
        "#split x and y train set\n",
        "y_train = train_data_cleaned2['winPlacePerc']\n",
        "x_train = train_data_cleaned2.iloc[:, train_data_cleaned2.columns != 'winPlacePerc']\n",
        "\n",
        "#create a test-train split to avoid overfitting\n",
        "#and to test on unseen data\n",
        "x_train_scaled, x_test_scaled, y_train, y_test = refactor(x_train, y_train, model)\n",
        "\n",
        "#set the \"past loop\" to be what we've done so far\n",
        "y = y_train\n",
        "x2 = x_train_scaled\n",
        "\n",
        "#define the \"past\" loop's accuracy score\n",
        "test_acc = model.score(x_test_scaled, y_test)\n",
        "old_test_acc = test_acc\n",
        "\n",
        "#do the iteration\n",
        "for i in range(24):\n",
        "    x1 = x2 #x1 = last loop, x2 = this loop\n",
        "    old_test_acc = test_acc\n",
        "    print(model.coef_)\n",
        "\n",
        "    #remove the lowest value and notify the user\n",
        "    smol = np.abs(model.coef_).argmin()\n",
        "    print(f\"removing index: {smol}\")\n",
        "    name = x1.columns[smol]\n",
        "    print(f\"name: {name} \\n\")\n",
        "\n",
        "    x2 = x1.drop([name], axis = 1)\n",
        "\n",
        "    print(f\"columns left to test {x2.columns} \\n\")\n",
        "\n",
        "    #refactor\n",
        "    x_train_scaled, x_test_scaled, y_train, y_test = refactor(x2, y, model)\n",
        "\n",
        "    #test accuracy\n",
        "    train_acc, test_acc = acc_check(x_train_scaled, x_test_scaled, y_train, y_test, model)\n",
        "\n",
        "    #expect an error at the end"
      ],
      "metadata": {
        "id": "GqOEMr8I3o_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ce9844d-9934-4cda-82c8-be670d8ec658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.37352481e-03  2.42727312e-02  1.20496504e-02 -2.13838764e-04\n",
            "  1.29365871e-03  2.71986630e-03 -1.95410327e-01 -1.20402774e-02\n",
            " -2.87255976e-02 -9.53771879e-02 -1.02201784e-04 -4.70251995e-02\n",
            " -1.19191461e-01  1.50369185e-01  1.40859546e-15  6.71567518e-03\n",
            "  2.37347917e-02 -6.37068886e-04  2.94631962e-03 -3.42203099e-03\n",
            "  7.47760479e-04  1.34401996e-01  2.93041760e-02  1.46245030e-02]\n",
            "removing index: 14\n",
            "name: rankPoints \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals',\n",
            "       'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill',\n",
            "       'matchDuration', 'maxPlace', 'numGroups', 'revives', 'rideDistance',\n",
            "       'roadKills', 'swimDistance', 'teamKills', 'vehicleDestroys',\n",
            "       'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.84%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 7.28712155e-03  2.50799112e-02  1.15435573e-02  1.92852353e-04\n",
            "  1.80605336e-03  2.03765941e-03 -1.95889229e-01 -1.16729418e-02\n",
            " -2.91811501e-02 -9.54521288e-02 -8.67236069e-05 -4.69009696e-02\n",
            " -1.23637355e-01  1.54940596e-01  7.17367822e-03  2.38164394e-02\n",
            " -5.59767073e-04  2.65679884e-03 -3.23042430e-03  1.16820947e-03\n",
            "  1.34017037e-01  2.89040406e-02  1.47326388e-02]\n",
            "removing index: 10\n",
            "name: longestKill \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals',\n",
            "       'killPlace', 'killPoints', 'kills', 'killStreaks', 'matchDuration',\n",
            "       'maxPlace', 'numGroups', 'revives', 'rideDistance', 'roadKills',\n",
            "       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n",
            "       'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.84%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 7.28512729e-03  2.50778322e-02  1.15416512e-02  1.89627793e-04\n",
            "  1.79811575e-03  2.03908777e-03 -1.95882741e-01 -1.16732940e-02\n",
            " -2.92131682e-02 -9.54536158e-02 -4.69035638e-02 -1.23629108e-01\n",
            "  1.54931204e-01  7.17592777e-03  2.38117697e-02 -5.59544309e-04\n",
            "  2.65721641e-03 -3.22886815e-03  1.16622830e-03  1.34002255e-01\n",
            "  2.89077039e-02  1.47315836e-02]\n",
            "removing index: 3\n",
            "name: DBNOs \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'headshotKills', 'heals',\n",
            "       'killPlace', 'killPoints', 'kills', 'killStreaks', 'matchDuration',\n",
            "       'maxPlace', 'numGroups', 'revives', 'rideDistance', 'roadKills',\n",
            "       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n",
            "       'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.84%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 0.00728303  0.02507104  0.01163652  0.00179856  0.0020398  -0.19587\n",
            " -0.01166988 -0.0292003  -0.09540142 -0.04689978 -0.12366944  0.15492269\n",
            "  0.00719038  0.02381252 -0.00056066  0.00265658 -0.00322384  0.00116579\n",
            "  0.13400736  0.02889009  0.0147344 ]\n",
            "removing index: 14\n",
            "name: roadKills \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'headshotKills', 'heals',\n",
            "       'killPlace', 'killPoints', 'kills', 'killStreaks', 'matchDuration',\n",
            "       'maxPlace', 'numGroups', 'revives', 'rideDistance', 'swimDistance',\n",
            "       'teamKills', 'vehicleDestroys', 'walkDistance', 'weaponsAcquired',\n",
            "       'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.84%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 0.00728494  0.0250791   0.01165021  0.00182275  0.00204427 -0.19585852\n",
            " -0.01166523 -0.02924655 -0.09541572 -0.04690566 -0.12374811  0.15499432\n",
            "  0.00719474  0.02374381  0.00265427 -0.00322381  0.00115626  0.13401485\n",
            "  0.02890083  0.01473254]\n",
            "removing index: 16\n",
            "name: vehicleDestroys \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'headshotKills', 'heals',\n",
            "       'killPlace', 'killPoints', 'kills', 'killStreaks', 'matchDuration',\n",
            "       'maxPlace', 'numGroups', 'revives', 'rideDistance', 'swimDistance',\n",
            "       'teamKills', 'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.83%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 0.00731383  0.02511189  0.0116889   0.00179085  0.00203454 -0.1958131\n",
            " -0.01166943 -0.02918349 -0.09541238 -0.04687796 -0.12377389  0.15501116\n",
            "  0.00720286  0.02383807  0.00265549 -0.0031082   0.13402505  0.0289038\n",
            "  0.01473174]\n",
            "removing index: 3\n",
            "name: headshotKills \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'heals', 'killPlace', 'killPoints',\n",
            "       'kills', 'killStreaks', 'matchDuration', 'maxPlace', 'numGroups',\n",
            "       'revives', 'rideDistance', 'swimDistance', 'teamKills', 'walkDistance',\n",
            "       'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.83%\n",
            "The accuracy for the test set is 84.71%\n",
            "\n",
            "[ 0.00727155  0.02510783  0.01184029  0.0020124  -0.19574842 -0.01168966\n",
            " -0.027939   -0.09551932 -0.04688567 -0.12351717  0.15475932  0.00719138\n",
            "  0.02384982  0.00267016 -0.00311461  0.13407333  0.02887425  0.01473748]\n",
            "removing index: 3\n",
            "name: heals \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'killPlace', 'killPoints', 'kills',\n",
            "       'killStreaks', 'matchDuration', 'maxPlace', 'numGroups', 'revives',\n",
            "       'rideDistance', 'swimDistance', 'teamKills', 'walkDistance',\n",
            "       'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.83%\n",
            "The accuracy for the test set is 84.70%\n",
            "\n",
            "[ 0.00733764  0.0258757   0.01199826 -0.1959037  -0.01171712 -0.02802282\n",
            " -0.09555407 -0.04682311 -0.12396179  0.15513699  0.00733577  0.02401192\n",
            "  0.00269424 -0.00311663  0.13417233  0.02895997  0.01472715]\n",
            "removing index: 12\n",
            "name: swimDistance \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'killPlace', 'killPoints', 'kills',\n",
            "       'killStreaks', 'matchDuration', 'maxPlace', 'numGroups', 'revives',\n",
            "       'rideDistance', 'teamKills', 'walkDistance', 'weaponsAcquired',\n",
            "       'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.82%\n",
            "The accuracy for the test set is 84.69%\n",
            "\n",
            "[ 0.00730761  0.02592225  0.01190933 -0.19598344 -0.01179047 -0.0280248\n",
            " -0.09562191 -0.04690455 -0.12344354  0.15466338  0.00732314  0.02400005\n",
            " -0.00309121  0.13463553  0.02891464  0.01474109]\n",
            "removing index: 12\n",
            "name: teamKills \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'killPlace', 'killPoints', 'kills',\n",
            "       'killStreaks', 'matchDuration', 'maxPlace', 'numGroups', 'revives',\n",
            "       'rideDistance', 'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.81%\n",
            "The accuracy for the test set is 84.67%\n",
            "\n",
            "[ 0.00736475  0.0260181   0.01124838 -0.19582381 -0.01174982 -0.0274411\n",
            " -0.09567969 -0.04700545 -0.12355173  0.15484863  0.00727528  0.02397467\n",
            "  0.13477405  0.02888651  0.01470407]\n",
            "removing index: 10\n",
            "name: revives \n",
            "\n",
            "columns left to test Index(['assists', 'boosts', 'damageDealt', 'killPlace', 'killPoints', 'kills',\n",
            "       'killStreaks', 'matchDuration', 'maxPlace', 'numGroups', 'rideDistance',\n",
            "       'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.76%\n",
            "The accuracy for the test set is 84.65%\n",
            "\n",
            "[ 0.0079347   0.02660133  0.01156714 -0.19622974 -0.01177938 -0.02732991\n",
            " -0.09519467 -0.04699608 -0.12486111  0.15499341  0.02407274  0.1352705\n",
            "  0.02881469  0.01465635]\n",
            "removing index: 0\n",
            "name: assists \n",
            "\n",
            "columns left to test Index(['boosts', 'damageDealt', 'killPlace', 'killPoints', 'kills',\n",
            "       'killStreaks', 'matchDuration', 'maxPlace', 'numGroups', 'rideDistance',\n",
            "       'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.71%\n",
            "The accuracy for the test set is 84.59%\n",
            "\n",
            "[ 0.0272243   0.01552655 -0.19604777 -0.01159741 -0.0290792  -0.09535178\n",
            " -0.04732419 -0.12545369  0.15457956  0.02409019  0.13601698  0.02926549\n",
            "  0.01467171]\n",
            "removing index: 3\n",
            "name: killPoints \n",
            "\n",
            "columns left to test Index(['boosts', 'damageDealt', 'killPlace', 'kills', 'killStreaks',\n",
            "       'matchDuration', 'maxPlace', 'numGroups', 'rideDistance',\n",
            "       'walkDistance', 'weaponsAcquired', 'winPoints'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.61%\n",
            "The accuracy for the test set is 84.45%\n",
            "\n",
            "[ 0.02668356  0.01277382 -0.19650966 -0.02853069 -0.09680124 -0.04635184\n",
            " -0.11689642  0.14758582  0.02417696  0.1365458   0.03032496  0.00992995]\n",
            "removing index: 11\n",
            "name: winPoints \n",
            "\n",
            "columns left to test Index(['boosts', 'damageDealt', 'killPlace', 'kills', 'killStreaks',\n",
            "       'matchDuration', 'maxPlace', 'numGroups', 'rideDistance',\n",
            "       'walkDistance', 'weaponsAcquired'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.50%\n",
            "The accuracy for the test set is 84.37%\n",
            "\n",
            "[ 0.02706583  0.01359638 -0.19749308 -0.0291045  -0.09706498 -0.04639201\n",
            " -0.12282903  0.15403185  0.02461067  0.1371458   0.03052137]\n",
            "removing index: 1\n",
            "name: damageDealt \n",
            "\n",
            "columns left to test Index(['boosts', 'killPlace', 'kills', 'killStreaks', 'matchDuration',\n",
            "       'maxPlace', 'numGroups', 'rideDistance', 'walkDistance',\n",
            "       'weaponsAcquired'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.47%\n",
            "The accuracy for the test set is 84.34%\n",
            "\n",
            "[ 0.02806673 -0.1978998  -0.0173808  -0.09771296 -0.04625211 -0.12508121\n",
            "  0.15572592  0.02479569  0.13721188  0.03086988]\n",
            "removing index: 2\n",
            "name: kills \n",
            "\n",
            "columns left to test Index(['boosts', 'killPlace', 'killStreaks', 'matchDuration', 'maxPlace',\n",
            "       'numGroups', 'rideDistance', 'walkDistance', 'weaponsAcquired'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.37%\n",
            "The accuracy for the test set is 84.25%\n",
            "\n",
            "[ 0.02431671 -0.19568241 -0.10830329 -0.04600929 -0.12535917  0.15563866\n",
            "  0.02543411  0.13803508  0.02986014]\n",
            "removing index: 0\n",
            "name: boosts \n",
            "\n",
            "columns left to test Index(['killPlace', 'killStreaks', 'matchDuration', 'maxPlace', 'numGroups',\n",
            "       'rideDistance', 'walkDistance', 'weaponsAcquired'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 84.04%\n",
            "The accuracy for the test set is 83.99%\n",
            "\n",
            "[-0.1988748  -0.10526689 -0.04752639 -0.12604389  0.15740954  0.02897711\n",
            "  0.1499007   0.03002372]\n",
            "removing index: 5\n",
            "name: rideDistance \n",
            "\n",
            "columns left to test Index(['killPlace', 'killStreaks', 'matchDuration', 'maxPlace', 'numGroups',\n",
            "       'walkDistance', 'weaponsAcquired'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 83.35%\n",
            "The accuracy for the test set is 83.32%\n",
            "\n",
            "[-0.20517561 -0.1093974  -0.03766749 -0.12972562  0.15964635  0.15317633\n",
            "  0.03296441]\n",
            "removing index: 6\n",
            "name: weaponsAcquired \n",
            "\n",
            "columns left to test Index(['killPlace', 'killStreaks', 'matchDuration', 'maxPlace', 'numGroups',\n",
            "       'walkDistance'],\n",
            "      dtype='object') \n",
            "\n",
            "The accuracy for the training set is 82.61%\n",
            "The accuracy for the test set is 82.54%\n",
            "\n",
            "[-0.22202849 -0.11728263 -0.03518854 -0.13480406  0.16455607  0.16331701]\n",
            "removing index: 2\n",
            "name: matchDuration \n",
            "\n",
            "columns left to test Index(['killPlace', 'killStreaks', 'maxPlace', 'numGroups', 'walkDistance'], dtype='object') \n",
            "\n",
            "The accuracy for the training set is 81.39%\n",
            "The accuracy for the test set is 81.26%\n",
            "\n",
            "[-0.2249239  -0.1160823  -0.27379497  0.30042229  0.15576452]\n",
            "removing index: 1\n",
            "name: killStreaks \n",
            "\n",
            "columns left to test Index(['killPlace', 'maxPlace', 'numGroups', 'walkDistance'], dtype='object') \n",
            "\n",
            "The accuracy for the training set is 77.12%\n",
            "The accuracy for the test set is 77.09%\n",
            "\n",
            "[-0.11302268 -0.21338686  0.24481527  0.18506004]\n",
            "removing index: 0\n",
            "name: killPlace \n",
            "\n",
            "columns left to test Index(['maxPlace', 'numGroups', 'walkDistance'], dtype='object') \n",
            "\n",
            "The accuracy for the training set is 68.34%\n",
            "The accuracy for the test set is 68.41%\n",
            "\n",
            "[-0.2063046   0.2403705   0.25285476]\n",
            "removing index: 0\n",
            "name: maxPlace \n",
            "\n",
            "columns left to test Index(['numGroups', 'walkDistance'], dtype='object') \n",
            "\n",
            "The accuracy for the training set is 68.23%\n",
            "The accuracy for the test set is 68.31%\n",
            "\n",
            "[0.03429357 0.25267519]\n",
            "removing index: 0\n",
            "name: numGroups \n",
            "\n",
            "columns left to test Index(['walkDistance'], dtype='object') \n",
            "\n",
            "The accuracy for the training set is 66.98%\n",
            "The accuracy for the test set is 67.02%\n",
            "\n",
            "[0.25011956]\n",
            "removing index: 0\n",
            "name: walkDistance \n",
            "\n",
            "columns left to test Index([], dtype='object') \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-192b7c0b46bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#refactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-a8d70ba5200d>\u001b[0m in \u001b[0;36mrefactor\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#scale the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[1;32m    840\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importantly, removing coefficients never raises r2, it can only lower it. That being said, this can still rank which attributes are considered most important to the linear regressor.\n",
        "\n",
        "From least important to most important:\n",
        "rankPoints, longestKill, DBNOs, roadKills, vehicleDestroys, headshotKills, heals (after removing heals, the r2 value starts to go down),\n",
        "swimDistance, teamKills, revives, assists, killPoints, winPoints, damageDealt, kills, boosts, rideDistance, weaponsAcquired, matchDuration, killStreaks, killPlace, maxPlace, numGroups, walkDistance|\n",
        "\n",
        "We know that rankPoints is inconsistent, and it seems the regressor figured that out. numGroups didn't seem like it would matter, as it is just the number of groups they have data for, though if there are less groups in a game, the relative placements will be higher. the walk distance is the most important stat, and that makes sense, as in a game of PUBG, there is a lot of walking, being the last one standing means you have the most time to walk.\n",
        "\n"
      ],
      "metadata": {
        "id": "cAcJ7XIa94oX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Mortem / Report\n",
        "\n",
        "This dataset was not a good choice due to its competition focus (this explains the `test_v2.csv` not having expected y values) and a seeming randomness that has not been resolved by any of our modeling attempts. This probably stems from some factor which was not encoded in the dataset that matters for winning at PUBG, such as total hours played when entering a match.\n",
        "\n",
        "Visualizing the results was rather difficult, due to the dimensionality of data and the local extrema that our models encounter. We attempted to use numerical evaluations in a similar way, but found them to be just as confounded as the visualizations. For example, the baseline mean-squared error (MSE) is 0.31. However, when a different model gives an MSE of 0.12, it is difficult to ascertain how much improvement has occurred between the two models."
      ],
      "metadata": {
        "id": "Yt3BVZc6Cjvg"
      }
    }
  ]
}